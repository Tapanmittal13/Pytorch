{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms #give access to popular datasets,arch,and image transformations for CV\n",
    "import torchvision.datasets as dsets \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset=dsets.MNIST(root='./data', #saves the data in current working base folder and download data in this data folder\n",
    "                          train=True,  #this means it is the training dataset\n",
    "                          transform=transforms.ToTensor(), #remember in pytorch we deal with tensors,so converting dataset to tensor\n",
    "                          download=True) #must when downloading for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) #this is a list becoz we can do len only on list,there are 60000 different digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]), tensor(5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0] #looking thru this dataset,first element in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0]) #its a tuple with first index having image matrix and second as the label of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0] #accessing 1st(0) element of 0 index tuple in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label\n",
    "train_dataset[0][1] #accessing 2nd[1] element of 0 index tuple in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input matrix\n",
    "train_dataset[0][0].size() #getting tensor size of 1st element of 0 index tuple\n",
    "#its basically our image of size 28*28 with channel=1 since its grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see the image \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img=train_dataset[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4610e977b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step1b-Loading MNIST Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=dsets.MNIST(root='./data' ,\n",
    "                         train=False, #putting train=false inorder to get work on test dataset\n",
    "                         transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset[0]) #everything is as per the train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2-Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just make the dataset iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total data: 60000\n",
    "\n",
    "minibatch:100\n",
    "\n",
    "Lets say we will do 5 Epochs (1 Epoch:Running through whole dataset once)\n",
    "\n",
    "Iterations=(total data/minibatch)* No. of Epochs=3000 (1 iteration:1 mini-batch forward and backward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "n_iters=(len(train_dataset)/batch_size)*epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Iterable Object:training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True) #sequence changes from epoch to epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Iterability\n",
    "import collections\n",
    "isinstance(train_loader,collections.Iterable) #if something is not iterable it returns false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Iterable Object:training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False) #we keep it false here since we will do only one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Iterability\n",
    "import collections\n",
    "isinstance(test_loader,collections.Iterable) #if something is not iterable it returns false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3-Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as linear regression since first step in logistic regression is linear regression\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "#     input_dim is x and output_dim is y\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        self.Linear=nn.Linear(input_dim,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.Linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-Instantiate Model CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].size()\n",
    "# flatten this one to 784 so that our model can interpret it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=28*28 \n",
    "output_dim=10\n",
    "model=LogisticRegressionModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5-Instantiate a loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Logistic Regression we use Cross Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss() #Cross Entropy automatically computes probability alongwith cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6-Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=.001\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prameter in Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Linear Regression it was simple 1D parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f4610ebee58>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "print(len(list(model.parameters()))) # it returns 2 becoz pytorch considers bias automatically along with other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Wx+B\n",
    "#(10,784)*(784*1)+(10,1)=(10,1)<--This is the output \n",
    "#Parameters:W\n",
    "print(list(model.parameters())[0].size())\n",
    "#bias parameter:B\n",
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7-Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 500. Loss 1.8781110048294067. Acuracy 64.\n",
      "Iterations 1000. Loss 1.5624001026153564. Acuracy 75.\n",
      "Iterations 1500. Loss 1.4899475574493408. Acuracy 79.\n",
      "Iterations 2000. Loss 1.2313628196716309. Acuracy 81.\n",
      "Iterations 2500. Loss 1.0622568130493164. Acuracy 82.\n",
      "Iterations 3000. Loss 0.9608088135719299. Acuracy 82.\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "for epoch in range(int(epochs)):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        #load images as Variables\n",
    "        images=Variable(images.view(-1,28*28))\n",
    "#         print(images.size())\n",
    "        labels=Variable(labels)\n",
    "        \n",
    "        #Clear Gradients wrt parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass to get output/logits\n",
    "        outputs=model(images)\n",
    "        \n",
    "        #cal loss:Softmax-->cross entropy loss\n",
    "        loss=criterion(outputs,labels)\n",
    "        \n",
    "        #getting gradients wrt parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1\n",
    "        \n",
    "        if iter%500==0:\n",
    "            #calculate Accuracy\n",
    "            correct=0\n",
    "            total=0\n",
    "            #iterate thru dataset\n",
    "            for images,labels in test_loader:\n",
    "                images=Variable(images.view(-1,28*28))\n",
    "                outputs=model(images)\n",
    "                \n",
    "                _,predicted=torch.max(outputs.data,1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                \n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=100*correct/total\n",
    "            \n",
    "            \n",
    "            #print(i)\n",
    "            print('Iterations {}. Loss {}. Acuracy {}.'.format(iter,loss.item(),accuracy))\n",
    "#print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break Down Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "tensor([[-0.3157, -1.1278, -0.5732, -0.1898,  0.0682, -0.4452, -1.0582,  2.9611,\n",
      "         -0.1814,  0.9543],\n",
      "        [ 0.2542,  0.1142,  1.6324,  1.3154, -1.5466,  0.4602,  1.3264, -2.0881,\n",
      "          0.7106, -1.4671],\n",
      "        [-0.9239,  2.2485,  0.2313,  0.0068, -0.5122, -0.3464, -0.1938, -0.1793,\n",
      "          0.1924, -0.4935],\n",
      "        [ 2.6718, -2.3437, -0.0171, -0.2708, -1.0280,  0.4053,  1.1157,  0.3682,\n",
      "         -0.5918, -0.3382],\n",
      "        [ 0.1778, -2.1332,  0.3311, -0.6511,  1.7146, -0.3929,  0.0810,  0.2448,\n",
      "          0.0890,  0.7950],\n",
      "        [-1.3566,  2.7041,  0.1985,  0.1653, -0.5508, -0.4326, -0.6996, -0.0199,\n",
      "          0.3870, -0.3548],\n",
      "        [-1.1490, -1.2940, -1.1332,  0.3644,  1.5149,  0.4308, -0.7292,  0.5520,\n",
      "          0.4754,  0.9525],\n",
      "        [-1.3114, -0.4513, -0.7951, -0.2549,  0.8585,  0.3627,  0.1227,  0.0010,\n",
      "          0.0928,  1.1865],\n",
      "        [ 0.5914, -0.7058,  0.7514, -1.3098,  0.6309,  0.3088,  0.6554, -1.0635,\n",
      "         -0.1594,  0.1152],\n",
      "        [-0.5211, -0.5917, -1.2485, -1.2048,  1.0811, -0.1531, -0.3653,  1.7675,\n",
      "          0.1247,  1.7216],\n",
      "        [ 3.4243, -1.8297,  0.5729,  1.2171, -0.9998,  1.0110, -0.3725, -1.3009,\n",
      "          0.6353, -1.7244],\n",
      "        [ 0.9463, -0.4914,  0.6034,  0.1185,  0.2645, -0.4536,  0.6667, -1.0423,\n",
      "          0.1550, -0.5897],\n",
      "        [-0.8801, -1.5559, -1.0833, -1.1153,  1.4708, -0.3363, -0.4679,  0.9609,\n",
      "          0.1193,  2.1088],\n",
      "        [ 2.9381, -2.5506, -0.1016, -0.3481, -0.4182,  0.6602, -0.3513, -0.3389,\n",
      "          0.6211,  0.0440],\n",
      "        [-1.5303,  2.6779, -0.0073,  0.3184, -1.0790, -0.3091, -0.1804, -0.2574,\n",
      "          0.2992, -0.3340],\n",
      "        [ 0.4693, -0.9659,  0.1788,  1.1833, -0.4465,  0.5858, -0.5307, -0.5002,\n",
      "          0.7729, -0.6876],\n",
      "        [-0.1536, -2.1564,  0.0257, -0.7366,  1.2219, -0.6111, -0.3721,  0.7186,\n",
      "          0.0826,  1.6306],\n",
      "        [ 0.2115, -1.5746, -0.7344,  0.3666, -0.2716, -0.4420, -0.5742,  2.6800,\n",
      "         -0.5619,  0.6919],\n",
      "        [-0.8174, -0.2104, -0.0979,  1.3356, -0.3307,  0.4880,  0.9449, -0.5241,\n",
      "          0.5816, -0.2313],\n",
      "        [-0.9158, -1.6318, -0.5898, -0.4378,  1.8846, -0.0071, -0.2431,  0.0044,\n",
      "         -0.0785,  1.2180],\n",
      "        [-1.0154, -0.1497, -1.6670,  0.0139,  0.5311,  0.3448, -1.2623,  1.7095,\n",
      "          0.3900,  1.4981],\n",
      "        [-0.9178, -1.3171, -0.0807,  0.2764,  0.1372,  0.3950,  2.3086, -1.3215,\n",
      "          0.1443, -0.0827],\n",
      "        [-0.2108, -0.0595,  0.1392, -0.6750,  0.7376, -1.2560,  1.2686, -0.0592,\n",
      "         -0.1100,  0.0437],\n",
      "        [ 0.1153, -1.0706, -0.6296,  0.3675, -0.0294,  1.4423,  0.1999, -0.7509,\n",
      "          0.7772,  0.1623],\n",
      "        [-0.6361, -0.9968, -0.0318, -0.0756,  1.3132, -0.2977, -0.1505,  0.2359,\n",
      "         -0.2888,  1.0376],\n",
      "        [ 4.1856, -2.8791,  0.4034, -1.2348, -0.4068,  1.1232,  1.1323, -0.6337,\n",
      "         -0.4442, -1.4420],\n",
      "        [ 0.0288, -1.1872, -0.5842, -0.1449,  0.4330, -0.2729, -0.5984,  1.8297,\n",
      "         -0.2543,  0.8433],\n",
      "        [-0.3186, -2.2892, -0.4268, -0.7700,  2.2449, -0.0542,  0.0692, -0.0918,\n",
      "          0.0674,  1.4840],\n",
      "        [ 2.6454, -2.3364,  0.2322,  1.1726, -1.2534,  0.6524, -0.0929, -0.4906,\n",
      "          0.6460, -0.5244],\n",
      "        [-1.2592,  1.4463, -0.3351,  0.2901, -0.5480,  0.0437,  0.2081, -0.1872,\n",
      "          0.2765, -0.1604],\n",
      "        [-1.0101, -0.0442, -1.0254,  2.1785, -1.2032,  0.9070, -0.4482,  0.4642,\n",
      "          0.0692,  0.0613],\n",
      "        [-1.0227,  1.0399, -0.2989,  0.2594, -0.3949,  0.0121, -0.2484,  0.0552,\n",
      "          0.1758,  0.1249],\n",
      "        [-1.1238, -0.7453, -0.5962,  2.2519, -0.5426,  1.2322, -0.4229, -0.9934,\n",
      "          0.3606, -0.1963],\n",
      "        [ 1.7089, -1.8898,  0.5828, -1.8231,  0.5954, -0.0287,  1.4866, -0.6762,\n",
      "         -0.1892, -0.4648],\n",
      "        [-0.9117, -0.0881,  0.6831, -0.4190, -0.1542, -0.3167, -1.3773,  1.9335,\n",
      "          0.6360,  0.5691],\n",
      "        [ 0.4129, -1.1534,  2.6564,  0.3614, -0.7560,  0.0846,  0.5767, -0.5175,\n",
      "          0.2613, -1.8693],\n",
      "        [-0.6255, -1.5471, -0.1311, -0.0949, -0.3135, -0.6762, -0.6452,  2.2857,\n",
      "         -0.4817,  1.0599],\n",
      "        [-1.4372,  2.0048, -0.4166,  0.0826, -0.6689, -0.1358, -0.1152, -0.0438,\n",
      "          0.3311, -0.0506],\n",
      "        [ 0.3211,  0.6413,  0.8834,  1.3633, -1.9066,  0.2949,  0.6012, -1.0581,\n",
      "          0.5880, -1.2898],\n",
      "        [-1.5132,  2.9794, -0.1328,  0.3049, -1.1908, -0.2232, -0.1628, -0.6935,\n",
      "          0.7017, -0.3345],\n",
      "        [-0.7469,  1.4974,  0.0846,  0.0455, -0.5411, -0.2900, -0.0420, -0.1245,\n",
      "          0.1236, -0.2899],\n",
      "        [-0.7892, -0.7569, -0.2972, -0.4148, -0.0973, -0.5309, -0.6516,  2.0829,\n",
      "         -0.3842,  1.2452],\n",
      "        [-1.9351, -0.6256, -0.4715, -0.4233,  2.1856, -0.7807, -1.0354,  0.4555,\n",
      "          0.3069,  1.4999],\n",
      "        [-0.4204,  0.8889,  1.1408, -0.2363, -0.1166, -0.4214,  0.3069, -1.0741,\n",
      "          0.5182, -0.3829],\n",
      "        [-1.2878,  0.1694,  0.0462,  1.2701, -0.8066,  0.4118,  0.4265, -0.1445,\n",
      "         -0.0001, -0.2941],\n",
      "        [ 0.2013, -1.1731, -0.6200,  1.7507, -0.6149,  1.4159,  0.0884, -1.2876,\n",
      "          0.7791, -0.3158],\n",
      "        [-1.6567,  0.1806,  0.0699,  0.7992, -0.1570,  0.2486, -0.0389, -0.1170,\n",
      "          0.3215,  0.2710],\n",
      "        [-0.6420, -0.2455,  1.3751, -0.3635,  0.4617, -0.5989,  0.5041, -0.4619,\n",
      "         -0.1489,  0.0762],\n",
      "        [-0.9222, -2.8595, -1.5022,  0.0293,  2.8042,  0.3359, -0.8313,  0.0378,\n",
      "          0.4448,  2.0656],\n",
      "        [-0.1037, -1.9436,  0.5386, -0.5514,  2.2300, -0.9616,  0.2482,  0.0487,\n",
      "         -0.2615,  1.0579],\n",
      "        [-0.1679, -0.8775,  0.1362,  0.3216, -0.4391,  0.5466,  2.2449, -1.2275,\n",
      "         -0.0688, -0.3173],\n",
      "        [-0.2018, -0.6278, -0.3757,  1.7812, -0.6816,  0.6233,  0.0867, -0.5995,\n",
      "         -0.1988,  0.0206],\n",
      "        [ 0.6329, -1.5119, -1.4914, -0.0609,  0.6265,  1.2408, -0.1718, -0.1576,\n",
      "         -0.0628,  0.5960],\n",
      "        [ 0.4494, -0.7719, -0.3724,  1.0202, -0.0847,  0.5468, -0.1695, -0.5719,\n",
      "          0.5430, -0.3971],\n",
      "        [ 0.1449, -0.6381,  1.0335, -0.4015,  0.6072, -0.9443,  0.6365, -0.7233,\n",
      "         -0.2238, -0.1994],\n",
      "        [ 1.3967, -2.2982, -0.4802,  0.6462, -0.7954,  0.9385,  0.4319, -0.6963,\n",
      "          1.3457, -0.0706],\n",
      "        [ 0.0542, -2.8902, -0.0962, -0.4578,  2.6740,  0.0104,  0.3037, -0.4232,\n",
      "         -0.2252,  1.0271],\n",
      "        [-0.9841,  2.2581,  0.0282,  0.1728, -0.6682, -0.3230, -0.5397, -0.1347,\n",
      "          0.2744, -0.2428],\n",
      "        [-0.0137, -2.0223, -0.8763, -1.0041,  1.7542, -0.3851, -0.2549,  0.8739,\n",
      "         -0.3611,  2.0560],\n",
      "        [-0.0079,  0.2407, -0.5936, -0.3459,  0.2621,  0.2193, -0.2070,  0.3746,\n",
      "          0.2670, -0.2707],\n",
      "        [ 0.0649, -1.6491, -0.8921,  0.7782,  0.1649, -0.4363, -0.1125,  1.9364,\n",
      "         -0.4994,  0.4875],\n",
      "        [-0.0859, -0.8406,  1.2987, -1.6481, -0.2233, -0.1749,  0.5271, -0.8729,\n",
      "          1.0278,  0.1733],\n",
      "        [-0.9249, -0.9702, -0.0945, -0.3600,  0.5031,  0.1214, -0.1594, -0.1687,\n",
      "          0.4901,  0.9134],\n",
      "        [-0.8634,  0.0375,  1.2825,  0.5802, -0.2922, -0.1514, -0.4231, -0.5329,\n",
      "          0.4407,  0.1548],\n",
      "        [-1.0959, -0.3999,  0.1836, -0.6913,  0.5334, -0.4461, -0.3737,  1.6836,\n",
      "          0.1617,  0.7647],\n",
      "        [-1.2163, -0.7353, -0.7755,  0.4318,  0.5606,  0.6070, -0.0955, -0.3078,\n",
      "          0.4802,  0.7329],\n",
      "        [ 0.3609, -0.3109,  0.7561,  0.0098,  0.4527, -0.8461,  0.6114,  0.0481,\n",
      "         -0.3727, -0.3884],\n",
      "        [-0.3513, -1.6655,  0.2888, -1.0261,  2.2265, -0.5390, -0.5369,  0.2513,\n",
      "         -0.0036,  0.8078],\n",
      "        [-1.4855, -0.6661, -0.4620,  2.6967, -0.6354,  0.8365, -1.0170, -0.8490,\n",
      "          0.7339, -0.0245],\n",
      "        [ 2.5236, -1.2716,  0.4744, -0.5777, -1.5358,  0.7033,  0.1863,  0.1364,\n",
      "         -0.7132, -0.5946],\n",
      "        [ 0.5484, -1.2789, -1.0287,  0.0945, -0.2247, -0.6022, -0.5737,  2.6516,\n",
      "         -0.5112,  0.6704],\n",
      "        [ 4.4549, -2.7127,  0.9246,  0.4622, -1.0319,  1.0527,  0.0790, -1.4515,\n",
      "          0.2118, -1.5547],\n",
      "        [ 1.4909, -1.1542,  1.9087,  1.2013, -0.9806, -0.0048,  0.6843, -0.5928,\n",
      "          0.5003, -1.8979],\n",
      "        [-1.4034,  1.0112,  0.2048, -0.1697, -0.6328, -0.1160, -1.0674,  0.9098,\n",
      "          1.2881,  0.5680],\n",
      "        [-1.5193,  2.2478, -0.3629, -0.0128, -0.9048, -0.1059, -0.0621, -0.1058,\n",
      "          0.5464, -0.2086],\n",
      "        [-1.6333,  0.4934, -0.7297, -0.3851,  0.8332, -0.8712, -0.5956,  1.4921,\n",
      "          0.1869,  0.9103],\n",
      "        [-0.2522,  0.2270, -0.2388,  2.2959, -1.0125,  0.9251, -0.4949, -0.9634,\n",
      "          0.4604, -0.8163],\n",
      "        [-1.0094, -0.3591,  0.4390, -0.6022, -0.0708, -0.5597, -0.0456,  1.6492,\n",
      "         -0.3108,  0.3014],\n",
      "        [-1.8175,  0.9287, -0.8841,  0.1158, -0.1020,  0.1578, -0.6355,  0.4754,\n",
      "          0.8323,  0.6557],\n",
      "        [-0.3749, -0.3480, -0.7635, -1.0278,  0.1539, -0.4272, -1.3035,  3.3341,\n",
      "          0.3754,  0.9338],\n",
      "        [-0.5913, -1.8152, -1.3616, -0.2259,  1.0338,  0.5311, -0.4083,  1.5974,\n",
      "         -0.5750,  1.6984],\n",
      "        [-0.3903, -1.6135,  0.6213, -0.5728, -0.0836,  0.0408,  2.5574, -0.2936,\n",
      "         -0.3120,  0.0864],\n",
      "        [-0.6950, -1.0738,  4.0044, -0.1189, -0.1796, -1.1968,  0.8098, -1.0329,\n",
      "          0.7534, -1.3647],\n",
      "        [-0.3580, -1.8161, -0.8674, -0.2529,  0.8593, -0.0632, -0.9724,  2.2186,\n",
      "         -0.2573,  1.3786],\n",
      "        [-0.6521, -0.0544, -0.4173, -0.4952,  0.8680,  0.6224, -0.6405, -0.6632,\n",
      "          1.0409,  0.2662],\n",
      "        [-0.8752, -2.5145, -1.0737,  0.1769,  3.0142,  0.3676, -0.4265, -0.3996,\n",
      "          0.1439,  1.3566],\n",
      "        [-1.9561,  0.5429, -0.4508, -0.7282, -0.0556, -0.8407, -1.0650,  2.9637,\n",
      "          0.3626,  1.0729],\n",
      "        [-0.1736, -1.4882, -1.1374,  1.7693, -0.3456,  0.9326,  0.6102, -0.3656,\n",
      "          0.1032, -0.1779],\n",
      "        [-0.3419, -1.5938,  0.8130, -1.0829,  1.0927, -0.5591,  2.2726,  0.0231,\n",
      "         -0.4578,  0.2216],\n",
      "        [-1.6276,  3.0103,  0.4410,  0.0623, -0.5293, -0.4248, -0.2387, -0.2426,\n",
      "          0.4926, -0.7178],\n",
      "        [ 0.2521, -0.7314, -0.2088,  2.8153, -1.1105,  0.7408, -1.2426, -0.4153,\n",
      "          0.7442, -0.5156],\n",
      "        [-1.1762, -0.5751,  0.3515, -0.6943,  0.1755, -0.3162,  2.6501, -1.0269,\n",
      "          0.2216,  0.1059],\n",
      "        [-0.8754,  0.1866,  0.1109, -0.6083,  0.4270,  0.0894, -0.1728, -0.0034,\n",
      "          0.7833,  0.5492],\n",
      "        [-0.9691, -0.7179, -0.8440,  2.6173, -1.4204,  1.1143, -1.1346,  0.5295,\n",
      "          0.5555,  0.1205],\n",
      "        [-2.2225,  1.6780, -0.0235,  0.1964, -0.5504, -0.1472,  0.2797, -0.5019,\n",
      "          0.8963, -0.0702],\n",
      "        [-0.7127, -0.5430, -0.4327, -1.4446,  2.2838, -0.5540,  0.1918, -0.3218,\n",
      "         -0.1192,  1.2546],\n",
      "        [-1.1591,  0.4298, -0.4880,  0.3764, -0.2245,  0.3240, -0.3102,  0.2284,\n",
      "          0.4129,  0.2870],\n",
      "        [-2.1005,  1.5970, -0.7443,  0.0947, -0.2146, -0.2080, -0.0768,  0.8756,\n",
      "          0.1448,  0.5338],\n",
      "        [ 0.7995, -1.2114,  0.8023, -0.7460, -0.3201,  0.2508,  2.1229, -0.9413,\n",
      "         -0.0172, -0.7920],\n",
      "        [-1.0536, -1.6932, -0.0028, -0.6210,  1.5457, -0.9190, -0.4100,  0.6132,\n",
      "         -0.0580,  2.2188]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)\n",
    "    if(iter_test==1):            \n",
    "        print(\"Outputs\")\n",
    "        print(outputs)\n",
    "    _,predicted=torch.max(outputs.data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)\n",
    "    if(iter_test==1):            \n",
    "        print(\"Outputs\")\n",
    "        print(outputs.size())\n",
    "    _,predicted=torch.max(outputs.data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "tensor([-0.3157, -1.1278, -0.5732, -0.1898,  0.0682, -0.4452, -1.0582,  2.9611,\n",
      "        -0.1814,  0.9543], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)\n",
    "    if(iter_test==1):            \n",
    "        print(\"Outputs\")\n",
    "        print(outputs[0,:])\n",
    "    _,predicted=torch.max(outputs.data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)         \n",
    "    _,predicted=torch.max(outputs.data,1)\n",
    "    if(iter_test==1):   \n",
    "        print(\"Prediction\")\n",
    "        print(predicted.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)         \n",
    "    _,predicted=torch.max(outputs.data,1)\n",
    "    if(iter_test==1):   \n",
    "        print(\"Prediction\")\n",
    "        print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "tensor(7)\n",
      "Label Size\n",
      "torch.Size([100])\n",
      "Label for Image 0\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)         \n",
    "    _,predicted=torch.max(outputs.data,1)\n",
    "    if(iter_test==1):   \n",
    "        print(\"Prediction\")\n",
    "        print(predicted[0])\n",
    "              \n",
    "              \n",
    "        print(\"Label Size\")\n",
    "        print(labels.size())\n",
    "          \n",
    "        print(\"Label for Image 0\")\n",
    "        print(labels[0])\n",
    "       \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "8274\n",
      "82.74000000000001\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "correct=0\n",
    "iter_test=0\n",
    "for images,labels in test_loader:\n",
    "    iter_test+=1\n",
    "    images=Variable(images.view(-1,28*28))\n",
    "    outputs=model(images)         \n",
    "    _,predicted=torch.max(outputs.data,1)\n",
    "    \n",
    "    #Total Number of labels\n",
    "    total+=labels.size(0)\n",
    "    \n",
    "    #Total correct Predictions\n",
    "    correct+=(predicted==labels).sum()\n",
    "    #correct=correct.numpy()\n",
    "    correct=correct.item()\n",
    "accuracy=(correct/total)*100\n",
    "\n",
    "print(total)\n",
    "print(correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model=False\n",
    "if save_model is True:\n",
    "    #saves only parameters\n",
    "    torch.save(model.state_dict(),\"Logistic_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
