{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforwad Neural Network with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1:- 1 Hidden Layer Feedforward Neural Network (uncomment for 2 layer hidden layer network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load Dataset\n",
    "# 2) Make dataset iterable\n",
    "# 3)Create Model class\n",
    "# 4) Instantiate Model Class\n",
    "# 5) Instantiate Loss Class\n",
    "# 6) Instantiate optimizer Class\n",
    "# 7) Tran Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import  torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dsets.MNIST(root='./data' ,train=True,transform=transforms.ToTensor())\n",
    "test_dataset=dsets.MNIST(root='./data' ,train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make datasets iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "\n",
    "n_iters=3000\n",
    "\n",
    "num_epochs=n_iters/(len(train_dataset)/batch_size)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetModel(nn.Module):\n",
    "#     input_dim is x and output_dim is y\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(FeedForwardNeuralNetModel,self).__init__()\n",
    "        #Linear function 1:784-->100\n",
    "        self.fc1=nn.Linear(input_dim,hidden_dim)\n",
    "        #Non-Linear 1\n",
    "        self.relu1=nn.ReLU()\n",
    "        #self.sigmoid=nn.Sigmoid()\n",
    "        #self.tanh=nn.Tanh()\n",
    "        \n",
    "         #Linear function 2:100-->100\n",
    "        #self.fc2=nn.Linear(hidden_dim,hidden_dim)\n",
    "        #self.relu2=nn.ReLU() \n",
    "        \n",
    "        #Linear function 3(readout layer)-->100-->10\n",
    "        self.fc3=nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Linear function 1\n",
    "        out=self.fc1(x)\n",
    "        #Non-Linear 1\n",
    "        out=self.relu1(out)\n",
    "        #out=self.sigmoid\n",
    "        #out=self.tanh\n",
    "        \n",
    "        #Linear function 2\n",
    "        #out=self.fc2\n",
    "        #Non-Linear 2\n",
    "        #out=self.relu2(out)\n",
    "        \n",
    "        #Linear function 3(readout layer)\n",
    "        out=self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=28*28\n",
    "hidden_dim=100\n",
    "output_dim=10\n",
    "\n",
    "model=FeedForwardNeuralNetModel(input_dim,hidden_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=.1\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 500. Loss 0.39282166957855225. Acuracy 90.\n",
      "Iterations 1000. Loss 0.4085947275161743. Acuracy 92.\n",
      "Iterations 1500. Loss 0.1666926145553589. Acuracy 93.\n",
      "Iterations 2000. Loss 0.13733436167240143. Acuracy 94.\n",
      "Iterations 2500. Loss 0.17649246752262115. Acuracy 95.\n",
      "Iterations 3000. Loss 0.19911079108715057. Acuracy 95.\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "for epoch in range(int(num_epochs)):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        images=Variable(images.view(-1,28*28))\n",
    "#         print(images.size())\n",
    "        labels=Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        \n",
    "        loss=criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1\n",
    "        \n",
    "        if iter%500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            \n",
    "            for images,labels in test_loader:\n",
    "                images=Variable(images.view(-1,28*28))\n",
    "                outputs=model(images)\n",
    "                \n",
    "                _,predicted=torch.max(outputs.data,1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                \n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=100*correct/total\n",
    "            \n",
    "            print('Iterations {}. Loss {}. Acuracy {}.'.format(iter,loss.item(),accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
